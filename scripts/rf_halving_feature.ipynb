{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64c87c9",
   "metadata": {},
   "source": [
    "##### 1.匯入套件與資料讀取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da9456ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from scipy.stats import zscore\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    roc_curve, auc as sk_auc, recall_score, precision_score, fbeta_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, FunctionTransformer\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64377a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 圖表儲存函數 ===\n",
    "import os\n",
    "def save_plot(fig, filename, model_name='rf_halving_feature'):  # ← 重新命名\n",
    "    \"\"\"\n",
    "    儲存圖表到 ../results/{model_name}/{filename}\n",
    "    \"\"\"\n",
    "    path = f'../results/{model_name}'\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    fig.savefig(f'{path}/{filename}', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98c155",
   "metadata": {},
   "source": [
    "##### 2.讀取資料與切分訓驗測集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c632a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/train_2025.csv')\n",
    "X = df.drop(columns=['claim_number', 'fraud'])  # 移除 ID 與目標欄位\n",
    "y = df['fraud']\n",
    "# 切分資料集：60% 訓練、20% 驗證、20% 測試\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27d677",
   "metadata": {},
   "source": [
    "##### 3.資料清洗與特徵欄位分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef1d227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下特徵工程跟logit一樣，可省略不看\n",
    "mask = ~X_train['zip_code'].astype(str).str.startswith('0')\n",
    "X_train = X_train[mask].reset_index(drop=True)\n",
    "y_train = y_train[mask].reset_index(drop=True)\n",
    "\n",
    "cat_cols = [\n",
    "    'gender', 'marital_status', 'high_education_ind', 'address_change_ind',\n",
    "    'living_status', 'zip_code', 'claim_date', 'claim_day_of_week', 'accident_site',\n",
    "    'witness_present_ind', 'channel', 'policy_report_filed_ind', 'vehicle_category', 'vehicle_color'\n",
    "]\n",
    "num_cols = [col for col in X_train.columns if col not in cat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe654cd6",
   "metadata": {},
   "source": [
    "##### 4.自訂欄位轉換器類別與函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b63a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_gender(X): \n",
    "    return (X == 'M').astype(int)\n",
    "\n",
    "def encode_living_status(X): \n",
    "    return (X == 'Own').astype(int)\n",
    "\n",
    "class Zip3Extractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        if hasattr(X, 'columns'):\n",
    "            self.feature_names_in_ = list(X.columns)\n",
    "        else:\n",
    "            self.feature_names_in_ = [f\"col_{i}\" for i in range(X.shape[1])]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_df = pd.DataFrame(X, columns=self.feature_names_in_)\n",
    "        return X_df.apply(lambda col: col.astype(str).str[:3])\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return [f\"{feat}_zip3\" for feat in (self.feature_names_in_ if input_features is None else input_features)]\n",
    "\n",
    "\n",
    "class ExtractMonthYear(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        if hasattr(X, 'columns'):\n",
    "            self.feature_names_in_ = list(X.columns)\n",
    "        else:\n",
    "            self.feature_names_in_ = [f\"col_{i}\" for i in range(X.shape[1])]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_series = pd.DataFrame(X, columns=self.feature_names_in_).iloc[:, 0]\n",
    "        date = pd.to_datetime(X_series, errors='coerce')\n",
    "        return date.dt.to_period('M').astype(str).to_frame()\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return [f\"{feat}_month_year\" for feat in (self.feature_names_in_ if input_features is None else input_features)]\n",
    "\n",
    "\n",
    "class TargetEncoderWrapper(TargetEncoder):\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return self.feature_names_in_ if input_features is None else input_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914f567",
   "metadata": {},
   "source": [
    "##### 5.設定各欄位的轉換流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6aec1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_witness_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent'))])\n",
    "gender_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('label_encoder', FunctionTransformer(encode_gender, validate=False, feature_names_out='one-to-one'))\n",
    "])\n",
    "zip3_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('zip3_extract', Zip3Extractor()),\n",
    "    ('target', TargetEncoderWrapper())\n",
    "])\n",
    "claim_date_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('extract_month_year', ExtractMonthYear()),\n",
    "    ('target', TargetEncoderWrapper())\n",
    "])\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "target_cat_cols = ['claim_day_of_week', 'accident_site', 'channel', 'vehicle_category', 'vehicle_color']\n",
    "target_cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('target', TargetEncoderWrapper())\n",
    "])\n",
    "\n",
    "transformers = [\n",
    "    ('marital_witness', marital_witness_pipeline, ['marital_status', 'witness_present_ind']),\n",
    "    ('gender', gender_pipeline, ['gender']),\n",
    "    ('zip_code', zip3_pipeline, ['zip_code']),\n",
    "    ('claim_date', claim_date_pipeline, ['claim_date']),\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat_imputer', target_cat_pipeline, target_cat_cols)\n",
    "]\n",
    "preprocessor = ColumnTransformer(transformers, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8019a7",
   "metadata": {},
   "source": [
    "##### 6.Halving Grid Search 訓練流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83deddf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Halving Iteration 0/6 ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Own'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m smote_nc\u001b[38;5;241m.\u001b[39mfit_resample(X_tr_transformed, y_tr_f)\n\u001b[0;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_resampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val_transformed)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     45\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_val_f, y_pred_proba)\n",
      "File \u001b[1;32md:\\users\\anaconda\\envs\\Fraud_Detection\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32md:\\users\\anaconda\\envs\\Fraud_Detection\\lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32md:\\users\\anaconda\\envs\\Fraud_Detection\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32md:\\users\\anaconda\\envs\\Fraud_Detection\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32md:\\users\\anaconda\\envs\\Fraud_Detection\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Own'"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100, 300],\n",
    "    \"max_depth\": [None, 10],\n",
    "    \"min_samples_split\": [2, 10],\n",
    "    \"min_samples_leaf\": [1, 4],\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "max_iter = 6\n",
    "factor = 2\n",
    "initial_frac = 1/32\n",
    "results = []\n",
    "current_candidates = grid.copy()\n",
    "\n",
    "start_time = time.time()\n",
    "for iteration in range(max_iter):\n",
    "    print(f\"\\n=== Halving Iteration {iteration}/{max_iter} ===\")\n",
    "    frac = min(initial_frac * (factor ** iteration), 1.0)\n",
    "    n_samples = int(len(X_train) * frac)\n",
    "    scores = []\n",
    "\n",
    "    for param in current_candidates:\n",
    "        aucs = []\n",
    "        for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "            X_tr_f = X_train.iloc[train_idx][:n_samples].copy()\n",
    "            y_tr_f = y_train.iloc[train_idx][:n_samples].copy()\n",
    "            X_val_f = X_train.iloc[val_idx].copy()\n",
    "            y_val_f = y_train.iloc[val_idx].copy()\n",
    "            z_scores = X_tr_f[num_cols].apply(zscore)\n",
    "            mask_no_outliers = (z_scores.abs() < 3).all(axis=1)\n",
    "            X_tr_f = X_tr_f.loc[mask_no_outliers].reset_index(drop=True)\n",
    "            y_tr_f = y_tr_f.loc[mask_no_outliers].reset_index(drop=True)\n",
    "            X_tr_transformed = preprocessor.fit_transform(X_tr_f, y_tr_f)\n",
    "            X_val_transformed = preprocessor.transform(X_val_f)\n",
    "            feature_names = preprocessor.get_feature_names_out()\n",
    "            cat_indices = [i for i, col in enumerate(feature_names) if col.startswith(('gender__', 'living_status__', 'zip_code__', 'claim_date__', 'cat_imputer__', 'remainder__'))]\n",
    "            smote_nc = SMOTENC(categorical_features=cat_indices, random_state=42)\n",
    "            X_resampled, y_resampled = smote_nc.fit_resample(X_tr_transformed, y_tr_f)\n",
    "            model = RandomForestClassifier(**param, random_state=42)\n",
    "            model.fit(X_resampled, y_resampled)\n",
    "            y_pred_proba = model.predict_proba(X_val_transformed)[:, 1]\n",
    "            auc = roc_auc_score(y_val_f, y_pred_proba)\n",
    "            aucs.append(auc)\n",
    "\n",
    "        mean_auc = np.mean(aucs)\n",
    "        scores.append((param, mean_auc))\n",
    "        print(f\"Param: {param} | AUC: {mean_auc:.4f}\")\n",
    "\n",
    "    if iteration == max_iter - 1:\n",
    "        results = scores.copy()\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    keep_top_k = max(1, len(scores) // factor)\n",
    "    current_candidates = [param for param, _ in scores[:keep_top_k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd1304",
   "metadata": {},
   "source": [
    "##### 6.最佳參數與測試集預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param, best_score = max(results, key=lambda x: x[1])\n",
    "print(\"\\n最佳超參數:\", best_param)\n",
    "print(\"平均 ROC-AUC:\", best_score)\n",
    "\n",
    "final_rf = RandomForestClassifier(random_state=42, n_jobs=-1, **best_param)\n",
    "final_rf.fit(X_resampled, y_resampled)\n",
    "\n",
    "X_valid_transformed = preprocessor.transform(X_valid)\n",
    "y_proba = final_rf.predict_proba(X_valid_transformed)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, y_proba)\n",
    "roc_auc = sk_auc(fpr, tpr)\n",
    "\n",
    "# 閾值搜尋\n",
    "best_threshold = 0\n",
    "best_prec = 0\n",
    "target_recall = 0.8\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "    recall = recall_score(y_valid, y_pred_thresh)\n",
    "    precision = precision_score(y_valid, y_pred_thresh)\n",
    "    if recall >= target_recall and precision > best_prec:\n",
    "        best_prec = precision\n",
    "        best_threshold = threshold\n",
    "print(f'最佳 Recall 閾值：{best_threshold:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed6f90f",
   "metadata": {},
   "source": [
    "##### 7.測試集預測與特徵重要性視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "y_test_proba = final_rf.predict_proba(X_test_transformed)[:, 1]\n",
    "y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "print(\"測試集績效報告：\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(f'auc: {roc_auc:.04f}')\n",
    "print(f'f2-score: {fbeta_score(y_test, y_test_pred, beta=2):.04f}')\n",
    "\n",
    "importances = final_rf.feature_importances_\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "feat_imp = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, len(feat_imp) * 0.3))\n",
    "plt.barh(feat_imp['feature'][::-1], feat_imp['importance'][::-1], color='teal')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"All Feature Importances (Random Forest)\")\n",
    "plt.tight_layout()\n",
    "save_plot(fig, \"feature_importance.png\", model_name='rf_halving_feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 特徵重要性繪圖與儲存 ===\n",
    "importances = final_rf.feature_importances_\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "fig = plt.figure(figsize=(10, len(feat_imp) * 0.3))\n",
    "plt.barh(feat_imp['feature'][::-1], feat_imp['importance'][::-1], color='teal')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"All Feature Importances (Random Forest)\")\n",
    "plt.tight_layout()\n",
    "save_plot(fig, \"feature_importance.png\", model_name='rf_halving_feature')\n",
    "plt.show()\n",
    "\n",
    "# === 混淆矩陣圖 ===\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "fig = plt.figure()\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xticks([0, 1], labels=['Pred 0', 'Pred 1'])\n",
    "plt.yticks([0, 1], labels=['True 0', 'True 1'])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
    "plt.tight_layout()\n",
    "save_plot(fig, \"confusion_matrix.png\", model_name='rf_halving_feature')\n",
    "plt.show()\n",
    "\n",
    "# === ROC 曲線 ===\n",
    "fig = plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "save_plot(fig, \"roc_curve.png\", model_name='rf_halving_feature')\n",
    "plt.show()\n",
    "\n",
    "# === PR 曲線 ===\n",
    "precision, recall, _ = precision_recall_curve(y_valid, y_proba)\n",
    "pr_auc = sk_auc(recall, precision)\n",
    "fig = plt.figure()\n",
    "plt.plot(recall, precision, label=f\"PR AUC = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "save_plot(fig, \"pr_curve.png\", model_name='rf_halving_feature')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fraud_Detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
